{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from lxml import etree\n",
    "import re\n",
    "\n",
    "def get_body_text(root):\n",
    "    '''Extraxts the text from the \"body\" tag of a etree xml TEI'''\n",
    "    \n",
    "    for child in root.getchildren():\n",
    "        if 'text' in child.tag:\n",
    "            for subchild in child.getchildren():\n",
    "                if 'body' in subchild.tag:\n",
    "                    return ' '.join(subchild.itertext())\n",
    "\n",
    "def pdf_to_xml(url):\n",
    "    '''Takes an url of a pdf as an input and returns its parsed xml TEI'''\n",
    "    \n",
    "    r = requests.get(url)                  # fetching the pdf\n",
    "    r = requests.post('http://cloud.science-miner.com/grobid/api/processFulltextDocument', \n",
    "                      files={'input': r.content})\n",
    "    return r.text\n",
    "\n",
    "def extract_entities(xml):\n",
    "    '''Takes an xml string and returns a json with the entities'''\n",
    "    \n",
    "    pattern = re.compile(r'<\\?xml.*\\?>')   # we need to get rid of the xml declaration\n",
    "    xml = pattern.sub('', xml)\n",
    "    root = etree.fromstring(xml)\n",
    "    fulltext = get_body_text(root)\n",
    "    alphanumeric = re.compile(\"([^\\w\\s']|_|\\n|\\t)+\")\n",
    "    fulltext = alphanumeric.sub(' ', fulltext)\n",
    "    query = '{\"text\": \"' + fulltext + '\", \"language\": {\"lang\": \"fr\"} }'\n",
    "    r = requests.post('http://localhost:8090/service/disambiguate', \n",
    "                      files={'query': query})\n",
    "    return r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Levenshtein import distance, hamming, jaro, ratio, setratio \n",
    "\n",
    "def compare(voc_one, voc_two):\n",
    "    storage = {}\n",
    "    result = {}\n",
    "    for string1 in voc_one:\n",
    "        for string2 in voc_two:\n",
    "            storage['levenshtein'].append(distance(string1, string2))\n",
    "            storage['hamming'].append(hamming(string1, string2))\n",
    "            storage['jaro'].append(jaro(string1, string2))\n",
    "    result = {'levenshtein-max': max(storage['levenshtein']),\n",
    "              'levenshtein-mean': sum(storage['levenshtein'])/len(storage['levenshtein']),\n",
    "              'levenshtein-min': min(storage['levenshtein']),\n",
    "              'hamming-max': max(result['hamming']),\n",
    "              'hamming-mean': sum(result['hamming'])/len(result['hamming']),\n",
    "              'hamming-min': min(result['levenshtein']),\n",
    "              'jaro-max': max(result['jaro']),\n",
    "              'jaro-mean': sum(result['jaro'])/len(result['jaro']),\n",
    "              'jaro-min': min(result['jaro']),\n",
    "              'set-ratio': setratio(a, b)}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-e38f5927dc01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m                                   \u001b[0;34m(\u001b[0m\u001b[0mdescriptors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                                   \u001b[0;34m(\u001b[0m\u001b[0magris\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                                   (agris, categories)]):\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'compairison'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "file = pd.read_excel('2020_export_Projet_Indexation_Automatique_Notice_accesTI_public_depuis2010_20200204.xlsx')\n",
    "file = file.loc[file.LANGUE_DOC==\"fre\"]\n",
    "\n",
    "results = pd.DataFrame()\n",
    "\n",
    "for i, row in file.iterrows():\n",
    "    pdf = row['ACCES_TEXTE_INTEGRAL']\n",
    "    if type(row[\"DESCRIPTEURS\"]) == str:\n",
    "        result = {}\n",
    "        descriptors = list(map(lambda x: x.strip(), row[\"DESCRIPTEURS\"].split(\";\")))\n",
    "        agris = list(map(lambda x: x.strip(), row[\"AGRIS\"].split(\";\")))\n",
    "        xml = pdf_to_xml(pdf)\n",
    "        text_json = extract_entities(xml)\n",
    "        text = json.loads(text_json)\n",
    "        entities = [part[\"rawName\"].strip() for part in text[\"entities\"]]\n",
    "        categories = [part[\"category\"].strip() for part in text[\"global_categories\"]]\n",
    "        for i, a, b in enumerate([(descriptors, entities),\n",
    "                                  (descriptors, categories),\n",
    "                                  (agris, entities),\n",
    "                                  (agris, categories)]):\n",
    "            result = compare(a, b)\n",
    "            result['compairison'] = i\n",
    "            result['pdf'] = pdf\n",
    "            results.append(result, ignore_index=True)\n",
    "    else:\n",
    "        print('not doing')\n",
    "\n",
    "    if i == 3:\n",
    "        break\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "print(row[\"DESCRIPTEURS\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
